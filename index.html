<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Analysing Discrete Self Supervised Speech Representation for Spoken Language Modeling</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


<section class="hero">
    <div class="hero-body">
        <div class="container is-max-desktop">
            <div class="columns is-centered">
                <div class="column has-text-centered">
                    <h1 class="title is-1 publication-title">Analysing Discrete Self Supervised Speech Representation for Spoken Language Modeling</h1>
                    <div class="is-size-5 publication-authors">
                        <!-- Paper authors -->
                        <span class="author-block">
                <a href="https://www.linkedin.com/in/amitay-sicherman/" target="_blank">Amitay Sicherman</a>,</span>
                        <span class="author-block">
                  <a href="https://www.cs.huji.ac.il/~adiyoss/" target="_blank">Yossi Adi</a></span>
                        </span>
                    </div>

                    <div class="is-size-5 publication-authors">
                        <span class="author-block">The Hebrew University of Jerusalem</span>
                    </div>

                    <div class="column has-text-centered">
                        <div class="publication-links">
                            <!-- Arxiv PDF link -->
                            <span class="link-block">
                        <a href="https://arxiv.org/pdf/2301.00591.pdf" target="_blank"
                           class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                            <!-- Github link -->
                            <span class="link-block">
                    <a href="https://github.com/slp-rl/SLM-Discrete-Representations" target="_blank"
                       class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                            <!-- ArXiv abstract Link -->
                            <span class="link-block">
                  <a href="https://arxiv.org/abs/2301.00591" target="_blank"
                     class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>

<!-- Paper abstract -->
<section class="section hero is-light">
    <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <h2 class="title is-3">Abstract</h2>
                <div class="content has-text-justified">
                    <p>
                        This work profoundly analyzes discrete self-supervised speech representations (units) through
                        the eyes of Generative Spoken Language Modeling (GSLM). Following the findings of such an
                        analysis, we propose practical improvements to the discrete unit for the GSLM. First, we start
                        comprehending these units by analyzing them in three axes: interpretation, visualization, and
                        resynthesis. Our analysis finds a high correlation between the speech units to phonemes and
                        phoneme families, while their correlation with speaker or gender is weaker. Additionally, we
                        found redundancies in the extracted units and claim that one reason may be the units' context.
                        Following this analysis, we propose a new, unsupervised metric to measure unit redundancies.
                        Finally, we use this metric to develop new methods that improve the robustness of units'
                        clustering and show significant improvement considering zero-resource speech metrics such as
                        ABX.
                    </p>
                </div>
            </div>
        </div>
    </div>
</section>
<!-- End paper abstract -->



<!-- Youtube video -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <!-- Paper video. -->
      <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video">
            <!-- Youtube embed code here -->
            <iframe src="https://youtube.com//embed/OwfyMg6zwqM" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End youtube video -->

<!-- Image carousel -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <!-- Your image here -->
        <img src="static/images/GSLM.png"/>
        <h2 class="subtitle has-text-centered">
				Generative Spoken Language Modeling (GSLM) main modules: (1) speech-to-unit (STU) - encodes the raw speech signal into a continuous representation and then quantized the representation to a sequence of discrete units (2) Unit language model (ULM) - a standard language model that gets the discrete unit as input (3) Unit-to-speech (UTS) - converts the discrete speech representation to a raw waveform.
				We can ignore the unit language model step to make a Speech resynthesis.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/cycel_method.png"/>
        <h2 class="subtitle has-text-centered">
			Units Visualization :          
			(1) Project the high-dimensional speech representation into 2D using the T-SNE 
			(2) Use the Voronoi diagram that converts the scatter plot into an area plot.
  			(3) Create a single label to represent each cluster using unit-phonemes alignment from the TIMIT.
			(4) Replace the unit id with their corresponding phonemes.
			(5) Color the area base on the phoneme and phoneme family. 			
			</h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/centers_phonemes.png"/>
        <h2 class="subtitle has-text-centered">
			Spatial view that contains information regarding the relationship between continuous representation, discrete units, and corresponding phonemes.
		</h2>
     </div>
     <div class="item">
      <!-- Your image here -->
      <img src="static/images/CR.png"/>
      <h2 class="subtitle has-text-centered">
		Circular Resynthesis (CR) : An unsupervised evaluation metric that measures discrete units' redundancies. 

      </h2>
    </div>
  </div>
</div>
</div>
</section>
<!-- End Image carousel -->

<!-- Paper poster -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/Poster.pdf" width="100%" height="1000">
          </iframe>
        
      </div>
    </div>
  </section>
<!--End paper poster -->

<!-- Paper poster -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Paper</h2>

      <iframe  src="static/pdfs/Paper.pdf" width="100%" height="1000">
          </iframe>
        
      </div>
    </div>
  </section>
<!--End paper poster -->

<!--BibTex citation -->
<section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
        <h2 class="title">BibTeX</h2>
        <pre><code>@article{sicherman2023analysing,
  title={Analysing Discrete Self Supervised Speech Representation for Spoken Language Modeling},
  author={Sicherman, Amitay and Adi, Yossi},
  journal={arXiv preprint arXiv:2301.00591},
  year={2023}
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->


<footer class="footer">
    <div class="container">
        <div class="columns is-centered">
            <div class="column is-8">
                <div class="content">

                    <p>
                        This page was built using the <a
                            href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic
                        Project Page Template</a>.
                        You are free to borrow the of this website, we just ask that you link back to this page in the
                        footer. <br> This website is licensed under a <a rel="license"
                                                                         href="http://creativecommons.org/licenses/by-sa/4.0/"
                                                                         target="_blank">Creative
                        Commons Attribution-ShareAlike 4.0 International License</a>.
                    </p>

                </div>
            </div>
        </div>
    </div>
</footer>

</body>
  </html>
